{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7726813b0f5247c3929ad399c7b451e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26c991b8cc60468ab6ba10a5577f215b",
              "IPY_MODEL_4919ae63a80c403cb15ef302751cc825",
              "IPY_MODEL_00eca09fe3a94ab5bf19dfa81d1d4f97"
            ],
            "layout": "IPY_MODEL_1d1c73c3fe3549b0b97ed25778c5270d"
          }
        },
        "26c991b8cc60468ab6ba10a5577f215b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e17eca26dad41588d53a2a41d5b4221",
            "placeholder": "​",
            "style": "IPY_MODEL_38e6deee786545e9b82d3a9f0bcfad3b",
            "value": "Epoch 299: 100%"
          }
        },
        "4919ae63a80c403cb15ef302751cc825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cff76087b446432fb4bd444e46801bbd",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ed1b37f163243e6b8069419ba075ff3",
            "value": 3
          }
        },
        "00eca09fe3a94ab5bf19dfa81d1d4f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e90eaad6724c71a772d8eb5184216b",
            "placeholder": "​",
            "style": "IPY_MODEL_ac9ab42f84b446548277a9208dc42418",
            "value": " 3/3 [00:00&lt;00:00,  3.83it/s, v_num=57tz]"
          }
        },
        "1d1c73c3fe3549b0b97ed25778c5270d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "0e17eca26dad41588d53a2a41d5b4221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38e6deee786545e9b82d3a9f0bcfad3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cff76087b446432fb4bd444e46801bbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ed1b37f163243e6b8069419ba075ff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20e90eaad6724c71a772d8eb5184216b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac9ab42f84b446548277a9208dc42418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e9cea3190fa47d58743afa69cf07744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5d057bf0905490e97b09ab6d4f241a4",
              "IPY_MODEL_0496d10466294101b4960fe0d833f9c6",
              "IPY_MODEL_871caec81dd9464ca9ef9c5a2da3136c"
            ],
            "layout": "IPY_MODEL_049a678d38a546549dc85fb4296e588c"
          }
        },
        "c5d057bf0905490e97b09ab6d4f241a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e119104e88654beaa3b2c45174f6628f",
            "placeholder": "​",
            "style": "IPY_MODEL_8148ad85b6584740aa552aaaed26d8a4",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "0496d10466294101b4960fe0d833f9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff1d99dce55d4451b9f9ab50b676fc81",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23d9160627a14f3a9b926e32391aabd3",
            "value": 8
          }
        },
        "871caec81dd9464ca9ef9c5a2da3136c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29b459e3ba57437a8429623c5fa1d2bc",
            "placeholder": "​",
            "style": "IPY_MODEL_1b60508b1ac04c4db7aa84d1cabdb186",
            "value": " 8/8 [00:00&lt;00:00, 35.77it/s]"
          }
        },
        "049a678d38a546549dc85fb4296e588c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e119104e88654beaa3b2c45174f6628f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8148ad85b6584740aa552aaaed26d8a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff1d99dce55d4451b9f9ab50b676fc81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23d9160627a14f3a9b926e32391aabd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29b459e3ba57437a8429623c5fa1d2bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b60508b1ac04c4db7aa84d1cabdb186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUmXr1D1ZSR"
      },
      "source": [
        "# Key-Value Attention for Thai Karaoke Character-level Machine Translation (Many-to-Many, encoder-decoder)\n",
        "\n",
        "In this homework, you will create an MT model with attention mechnism that coverts names of Thai 2019 MP candidates from Thai script to Roman(Latin) script. E.g. นิยม-->niyom\n",
        "\n",
        "The use of Pytorch Lightning is optional but recommended. You can use Pytorch if you prefer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning wandb\n",
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf"
      ],
      "metadata": {
        "id": "18KMSkqZ-Pt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7385aadf-7a63-42bb-cfc0-f7e2e3688dba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightning\n",
            "  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.11)\n",
            "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2025.3.2)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (24.2)\n",
            "Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (2.6.0+cu124)\n",
            "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
            "  Downloading torchmetrics-1.7.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning) (4.13.2)\n",
            "Collecting pytorch-lightning (from lightning)\n",
            "  Downloading pytorch_lightning-2.5.1.post0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.2.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.29.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.15)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<4.0,>=2.1.0->lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.20.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n",
            "Downloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.2-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.5/962.5 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.1.post0-py3-none-any.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.1/823.1 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning, lightning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-2.5.1.post0 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-lightning-2.5.1.post0 torchmetrics-1.7.2\n",
            "--2025-05-31 13:23:28--  https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf [following]\n",
            "--2025-05-31 13:23:29--  https://raw.githubusercontent.com/Phonbopit/sarabun-webfont/master/fonts/thsarabunnew-webfont.ttf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 98308 (96K) [application/octet-stream]\n",
            "Saving to: ‘thsarabunnew-webfont.ttf’\n",
            "\n",
            "thsarabunnew-webfon 100%[===================>]  96.00K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2025-05-31 13:23:29 (11.8 MB/s) - ‘thsarabunnew-webfont.ttf’ saved [98308/98308]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCBCWKARZEx",
        "outputId": "4c91c81f-8753-416d-8977-64606df4b48b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using legacy-service, which is deprecated. If this is unintentional, you can fix it by ensuring you do not call `wandb.require('legacy-service')` and do not set the WANDB_X_REQUIRE_LEGACY_SERVICE environment variable.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcharoonroj-amo\u001b[0m (\u001b[33mcharoonroj-amo-chulalongkorn-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka2TN8IV1ZSU"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n",
        "mpl.rc('font', family='TH Sarabun New')\n",
        "import torch\n",
        "# import torchtext\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import lightning as L\n",
        "import numpy as np\n",
        "\n",
        "import random"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-f_s6vX1ZSZ"
      },
      "source": [
        "## Load Dataset\n",
        "We have generated a toy dataset using names of Thai MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n",
        "\n",
        "```\n",
        "ไกรสีห์ kraisi\n",
        "พัชรี phatri\n",
        "ธีระ thira\n",
        "วุฒิกร wutthikon\n",
        "ไสว sawai\n",
        "สัมภาษณ์  samphat\n",
        "วศิน wasin\n",
        "ทินวัฒน์ thinwat\n",
        "ศักดินัย sakdinai\n",
        "สุรศักดิ์ surasak\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv"
      ],
      "metadata": {
        "id": "Jte-Csrf-4kd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913aceae-6527-4695-ab1e-e26a4cdcff85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-31 13:25:38--  https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/mp_name_th_en.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 324399 (317K) [text/plain]\n",
            "Saving to: ‘mp_name_th_en.csv’\n",
            "\n",
            "mp_name_th_en.csv   100%[===================>] 316.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-05-31 13:25:38 (17.9 MB/s) - ‘mp_name_th_en.csv’ saved [324399/324399]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9zXp7KH1ZSa"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('mp_name_th_en.csv') as csvfile:\n",
        "    readCSV = csv.reader(csvfile, delimiter=',')\n",
        "    name_th = []\n",
        "    name_en = []\n",
        "    for row in readCSV:\n",
        "        temp_th = row[0]\n",
        "        temp_en = row[1]\n",
        "\n",
        "        name_th.append(temp_th)\n",
        "        name_en.append(temp_en)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCsqrXxu1ZSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d979294-12df-45be-b2d5-38ffcd83e371"
      },
      "source": [
        "for th, en in zip(name_th[:10],name_en[:10]):\n",
        "    print(th,en)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ไกรสีห์ kraisi\n",
            "พัชรี phatri\n",
            "ธีระ thira\n",
            "วุฒิกร wutthikon\n",
            "ไสว sawai\n",
            "สัมภาษณ์  samphat\n",
            "วศิน wasin\n",
            "ทินวัฒน์ thinwat\n",
            "ศักดินัย sakdinai\n",
            "สุรศักดิ์ surasak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvW8xqT81ZSh"
      },
      "source": [
        "## TODO1: Preprocess dataset\n",
        "* You will need 2 vocabularies (1 for input and another for output)\n",
        "* DON'T FORGET TO INCLUDE special token for padding (for both input and output)\n",
        "* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rv1Xd9A1ZSi",
        "outputId": "e790fc69-8f6f-4179-87a9-04ca2bd91109",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Preprocessing\n",
        "input_chars = list(set(''.join(name_th)))\n",
        "output_chars = list(set(''.join(name_en)))\n",
        "data_size, vocab_size = len(name_th), len(input_chars)+1\n",
        "output_vocab_size = len(output_chars)+2#+2 for special end of sentence token/PADDING\n",
        "print('There are %d lines and %d unique characters in your input data.' % (data_size, vocab_size))\n",
        "maxlen = len( max(name_th, key=len)) #max input length\n",
        "maxlen_out = len( max(name_en, key=len)) #max input length"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10887 lines and 65 unique characters in your input data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo381I_t1ZSm",
        "outputId": "2bd9f6b6-d209-473c-b33c-0e5d84ecd2e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Max input length:\", maxlen)\n",
        "print(\"Max output length:\", maxlen_out)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max input length: 20\n",
            "Max output length: 19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_chars = sorted(input_chars)\n",
        "sorted_chars.insert(0, \"<PAD>\")\n",
        "# sorted_chars.insert(1, \"</s>\")\n",
        "\n",
        "sorted_output_chars = sorted(output_chars)\n",
        "sorted_output_chars.insert(0, \"<PAD>\")\n",
        "sorted_output_chars.insert(1, \"</s>\")\n",
        "\n",
        "input_stoi = { c:i for i, c in enumerate(sorted_chars) }\n",
        "input_itos = { i:c for i, c in enumerate(sorted_chars)}\n",
        "input_encode = lambda sentence: [input_stoi[c] for c in sentence]\n",
        "input_decode = lambda encoding: \"\".join([input_itos[i] for i in encoding])\n",
        "\n",
        "output_stoi = { c:i for i, c in enumerate(sorted_output_chars) }\n",
        "output_itos = { i:c for i, c in enumerate(sorted_output_chars)}\n",
        "output_encode = lambda sentence: [output_stoi[c] for c in sentence]\n",
        "output_decode = lambda encoding: \"\".join([output_itos[i] for i in encoding])\n",
        "\n",
        "print(input_encode(name_th[0]))\n",
        "print(input_decode(input_encode(name_th[0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIPHULFwjc1i",
        "outputId": "823ac113-9c06-4c48-fbd4-a5263e843d69"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[58, 2, 34, 39, 49, 40, 64]\n",
            "ไกรสีห์\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_stoi)\n",
        "print(output_stoi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vVj6OWHjiip",
        "outputId": "9e7dd0a2-9f2e-43da-b9f9-3e29631f9019"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<PAD>': 0, ' ': 1, 'ก': 2, 'ข': 3, 'ค': 4, 'ฆ': 5, 'ง': 6, 'จ': 7, 'ฉ': 8, 'ช': 9, 'ซ': 10, 'ฌ': 11, 'ญ': 12, 'ฎ': 13, 'ฏ': 14, 'ฐ': 15, 'ฑ': 16, 'ฒ': 17, 'ณ': 18, 'ด': 19, 'ต': 20, 'ถ': 21, 'ท': 22, 'ธ': 23, 'น': 24, 'บ': 25, 'ป': 26, 'ผ': 27, 'ฝ': 28, 'พ': 29, 'ฟ': 30, 'ภ': 31, 'ม': 32, 'ย': 33, 'ร': 34, 'ล': 35, 'ว': 36, 'ศ': 37, 'ษ': 38, 'ส': 39, 'ห': 40, 'ฬ': 41, 'อ': 42, 'ฮ': 43, 'ะ': 44, 'ั': 45, 'า': 46, 'ำ': 47, 'ิ': 48, 'ี': 49, 'ึ': 50, 'ื': 51, 'ุ': 52, 'ู': 53, 'เ': 54, 'แ': 55, 'โ': 56, 'ใ': 57, 'ไ': 58, '็': 59, '่': 60, '้': 61, '๊': 62, '๋': 63, '์': 64}\n",
            "{'<PAD>': 0, '</s>': 1, '-': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'w': 22, 'y': 23}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "for line in name_th:\n",
        "    X.append(torch.tensor(input_encode(line)))\n",
        "Y = []\n",
        "for line in name_en:\n",
        "    Y.append(torch.tensor(output_encode(line)))\n",
        "\n",
        "X = nn.utils.rnn.pad_sequence(X, batch_first=True)\n",
        "Y = nn.utils.rnn.pad_sequence(Y, batch_first=True)"
      ],
      "metadata": {
        "id": "IMrwB-90kWbB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ty = len(max(Y, key=len))\n",
        "Ty"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vwEMTUTpjZ5",
        "outputId": "57b2f2ad-3998-445e-8e19-4beedaa9aa91"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.types import Tensor"
      ],
      "metadata": {
        "id": "W3aXyJBEC-j_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.encoded = X\n",
        "    self.label = y\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return {\"x\": self.encoded[idx], \"y\": self.label[idx]}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encoded)"
      ],
      "metadata": {
        "id": "-yirzlseC9NS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataModule(L.LightningDataModule):\n",
        "\n",
        "  def __init__(self, train_data, y, batch_size, num_workers=0):\n",
        "      super().__init__()\n",
        "      self.train_data = train_data\n",
        "      self.y = y\n",
        "      self.batch_size = batch_size\n",
        "      self.num_workers = num_workers\n",
        "\n",
        "\n",
        "  def setup(self, stage: str):\n",
        "    pass\n",
        "\n",
        "  def collate_fn(self, batch):\n",
        "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "    return {\"x\": one_hot_x.float(), \"y\": torch.stack([b[\"y\"] for b in batch])}\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    train_dataset = NameDataset(self.train_data, self.y)\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              batch_size=self.batch_size,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=self.collate_fn,\n",
        "                              num_workers=self.num_workers)\n",
        "    return train_loader\n"
      ],
      "metadata": {
        "id": "qUPAB7LTDFOy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFSG1FqK1ZSy"
      },
      "source": [
        "# Attention Mechanism\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO 2: Code your own (key-value) attention mechnism\n",
        "* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n",
        "* fill code for one_step_attention function\n",
        "\n"
      ],
      "metadata": {
        "id": "HAlOrhbismQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_step_attention(h: Tensor, s_prev: Tensor, linear_1: nn.Linear, linear_2: nn.Linear):\n",
        "    # (enc) h.shape = batch, seq_len, hidden_dim\n",
        "    # (dec) s_prev.shape = batch, hidden_dim\n",
        "\n",
        "    #Split into Key-Value\n",
        "    hidden_dim = h.shape[-1]\n",
        "    key_dim = hidden_dim // 2\n",
        "    value_dim = key_dim\n",
        "    key, value = torch.split(h, [key_dim, value_dim], dim=-1)\n",
        "\n",
        "    seq_len = h.shape[1]\n",
        "    #do concat with s_prev.\n",
        "    s_prev = s_prev.unsqueeze(1).repeat(1, seq_len, 1)\n",
        "    concat = torch.cat([key, s_prev], dim=-1)\n",
        "    #hint: you will need to use s_prev.repeat(...) somehow so that it has the same dimension as the key\n",
        "    #hint2: s_prev.unsqueeze() could also be useful\n",
        "\n",
        "    #Attention function###\n",
        "    # use layer(s) from your model to calculate attention_scores and then softmax\n",
        "    # calculate a context vector\n",
        "    e = F.tanh(linear_1(concat))\n",
        "    energies = F.relu(linear_2(e))\n",
        "    attention_scores = F.softmax(energies, dim=1)\n",
        "    context = torch.sum(attention_scores * value, dim=1)\n",
        "\n",
        "    return context, attention_scores"
      ],
      "metadata": {
        "id": "avnlc6p9BZDv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Translation Model"
      ],
      "metadata": {
        "id": "6zWN02ZtuOIU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0phyUQYg1ZS8"
      },
      "source": [
        "## TODO3: Create and train your encoder/decoder model here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji_rUPhK1ZS9"
      },
      "source": [
        "output_vocab = output_stoi\n",
        "class AttentionModel(L.LightningModule):\n",
        "    def __init__(self, learning_rate, criterion):\n",
        "\n",
        "        super().__init__()\n",
        "        self.n_h = 32 #hidden dimensions for encoder\n",
        "        self.n_s = 64 #hidden dimensions for decoder\n",
        "        self.learning_rate = learning_rate\n",
        "        self.criterion = criterion\n",
        "\n",
        "        #encoder can be any RNN of your choice\n",
        "        bidirection = True\n",
        "        self.num_directions = 2 if bidirection else 1\n",
        "        self.lstm = nn.LSTM(len(input_stoi), self.n_h, bidirectional=bidirection, batch_first=True)\n",
        "\n",
        "        #decoder has to be (any) RNNCell since we will need to calculate attention for each timestep manually\n",
        "        self.decoder_lstm_cell = nn.LSTMCell(self.n_s//2, self.n_s)\n",
        "        self.output_layer = nn.Linear(self.n_s, len(output_stoi))\n",
        "\n",
        "        #attention\n",
        "        self.fc1 = nn.Linear(self.n_h*self.num_directions*3//2, self.n_h)\n",
        "        self.fc2 = nn.Linear(self.n_h, 1)\n",
        "\n",
        "    def forward(self, src, return_attention=False): #use return_attention only when you want to get the attention scores for visualizing\n",
        "        #pass the input to the encoder\n",
        "        lstm_out, _ = self.lstm(src)\n",
        "\n",
        "        #Initialize the LSTM states. We have to do this since we are using LSTMCell (https://pytorch.org/docs/stable/generated/torch.nn.LSTMCell.html)\n",
        "        #These states will get updated while we are decoding\n",
        "        decoder_s = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        decoder_c = torch.randn(src.shape[0], self.n_s).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "\n",
        "        #Iterate until max_output_length (Decoding)\n",
        "        prediction = torch.zeros((src.shape[0], Ty, len(output_vocab))).to(self.decoder_lstm_cell.weight_ih.device)\n",
        "        attention_scores = [] #to store the score for each step\n",
        "        for t in range(Ty):\n",
        "\n",
        "            #Perform one step of the attention mechanism to calculate the context vector at timestep t\n",
        "            context, attention_score = one_step_attention(lstm_out, decoder_s, self.fc1, self.fc2)\n",
        "\n",
        "            # Feed the context vector to the decoder.\n",
        "            decoder_s, decoder_c = self.decoder_lstm_cell(context, (decoder_s, decoder_c))\n",
        "            # Pass the decoder hidden output to the output layer (softmax)\n",
        "            out = self.output_layer(decoder_s)\n",
        "            # Put the predicted output into the list for this timestep\n",
        "            prediction[:, t] = out\n",
        "            attention_scores.append(attention_score)\n",
        "\n",
        "        return (prediction, attention_scores if return_attention else None)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        src = batch['x']\n",
        "        target = batch['y']\n",
        "        prediction,_ = self(src)\n",
        "        prediction = prediction.reshape(-1, len(output_vocab))\n",
        "        target = target.reshape(-1)\n",
        "        loss = self.criterion(prediction, target)\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
        "        src = batch['x']\n",
        "        with torch.no_grad():\n",
        "          prediction, attention_scores = self(src, return_attention=True)\n",
        "          prediction = F.softmax(prediction, dim=-1)\n",
        "          prediction = torch.argmax(prediction, dim=-1)\n",
        "          for pred in prediction:\n",
        "            print(\"\".join(output_decode(pred.cpu().numpy())))\n",
        "            # print(\"\".join(output_vocab.lookup_tokens(pred.cpu().numpy())))\n",
        "        return prediction, attention_scores\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "model = AttentionModel(lr,criterion)"
      ],
      "metadata": {
        "id": "pSM9dgDcCz1E"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_module = NameDataModule(X, Y, batch_size = 4096)"
      ],
      "metadata": {
        "id": "RqrvmJalDLzF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lightning import Trainer\n",
        "from lightning.pytorch.loggers import WandbLogger\n",
        "wandb_logger = WandbLogger(project=\"hw3.1_attention\")"
      ],
      "metadata": {
        "id": "_sFjzKX8SECo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGWSzS-X1ZTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "488ddbfb-bdd4-48c3-85fd-0caa635cd779"
      },
      "source": [
        "trainer = L.Trainer(\n",
        "    max_epochs=300,\n",
        "    logger=wandb_logger\n",
        ")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO: GPU available: True (cuda), used: True\n",
            "INFO:lightning.pytorch.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO: TPU available: False, using: 0 TPU cores\n",
            "INFO:lightning.pytorch.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO: HPU available: False, using: 0 HPUs\n",
            "INFO:lightning.pytorch.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZMi782c1ZTQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729,
          "referenced_widgets": [
            "7726813b0f5247c3929ad399c7b451e3",
            "26c991b8cc60468ab6ba10a5577f215b",
            "4919ae63a80c403cb15ef302751cc825",
            "00eca09fe3a94ab5bf19dfa81d1d4f97",
            "1d1c73c3fe3549b0b97ed25778c5270d",
            "0e17eca26dad41588d53a2a41d5b4221",
            "38e6deee786545e9b82d3a9f0bcfad3b",
            "cff76087b446432fb4bd444e46801bbd",
            "1ed1b37f163243e6b8069419ba075ff3",
            "20e90eaad6724c71a772d8eb5184216b",
            "ac9ab42f84b446548277a9208dc42418"
          ]
        },
        "outputId": "ad3a374c-5bd1-4643-d8af-0a2495231fb3"
      },
      "source": [
        "trainer.fit(model, data_module)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "/usr/local/lib/python3.11/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory ./hw3.1_attention/jzcx57tz/checkpoints exists and is not empty.\n",
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO: \n",
            "  | Name              | Type             | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | criterion         | CrossEntropyLoss | 0      | train\n",
            "1 | lstm              | LSTM             | 25.3 K | train\n",
            "2 | decoder_lstm_cell | LSTMCell         | 25.1 K | train\n",
            "3 | output_layer      | Linear           | 1.6 K  | train\n",
            "4 | fc1               | Linear           | 3.1 K  | train\n",
            "5 | fc2               | Linear           | 33     | train\n",
            "---------------------------------------------------------------\n",
            "55.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "55.1 K    Total params\n",
            "0.221     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n",
            "INFO:lightning.pytorch.callbacks.model_summary:\n",
            "  | Name              | Type             | Params | Mode \n",
            "---------------------------------------------------------------\n",
            "0 | criterion         | CrossEntropyLoss | 0      | train\n",
            "1 | lstm              | LSTM             | 25.3 K | train\n",
            "2 | decoder_lstm_cell | LSTMCell         | 25.1 K | train\n",
            "3 | output_layer      | Linear           | 1.6 K  | train\n",
            "4 | fc1               | Linear           | 3.1 K  | train\n",
            "5 | fc2               | Linear           | 33     | train\n",
            "---------------------------------------------------------------\n",
            "55.1 K    Trainable params\n",
            "0         Non-trainable params\n",
            "55.1 K    Total params\n",
            "0.221     Total estimated model params size (MB)\n",
            "6         Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7726813b0f5247c3929ad399c7b451e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: `Trainer.fit` stopped: `max_epochs=300` reached.\n",
            "INFO:lightning.pytorch.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=300` reached.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5BLw1Ir1ZTT"
      },
      "source": [
        "# Test Your Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO4: Test your model on 5 examples of your choice including your name!\n",
        "\n",
        "Example Output:\n",
        "```\n",
        "prayutthatha</s></s>aa</s></s>a</s>\n",
        "somchai</s></s></s></s>a</s></s>a</s></s></s></s></s>\n",
        "thanathon</s></s></s></s></s></s></s></s></s></s></s>\n",
        "newin</s>i</s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "suthep</s>he</s></s></s></s></s></s></s></s></s></s></s>\n",
        "prawit</s></s></s></s></s></s></s></s></s></s></s></s></s></s>\n",
        "chatchachatti</s></s>i</s></s></s></s>\n",
        "```\n",
        "\n",
        "<font color='blue'>Paste your model predictions in MyCourseVille</font>"
      ],
      "metadata": {
        "id": "VRLjZzBMtCdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['ประยุทธ์','สมชาย','ธนาธร','เนวิน','สุเทพ','ประวิตร์','ชัชชาติ','จรูญโรจน์']\n",
        "predict_data = []\n",
        "for line in EXAMPLES:\n",
        "    line = [l for l in line] #change from string to list\n",
        "    predict_data.append(torch.tensor(input_encode(line)))\n",
        "\n",
        "print(len(predict_data))\n",
        "def collate_fn(batch):\n",
        "    one_hot_x = torch.stack([F.one_hot(b[\"x\"], num_classes=len(input_stoi)) for b in batch])\n",
        "    return {\"x\": one_hot_x.float()}\n",
        "\n",
        "predict_data = nn.utils.rnn.pad_sequence(predict_data, batch_first = True)\n",
        "predict_dataset = NameDataset(predict_data, torch.tensor([torch.tensor(0)]*len(predict_data)))\n",
        "predict_loader = DataLoader(predict_dataset,\n",
        "                          batch_size = 1,\n",
        "                          shuffle = False,\n",
        "                          collate_fn = collate_fn,\n",
        "                          num_workers = 0)"
      ],
      "metadata": {
        "id": "6stNACsUP9h-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d132de78-128c-4776-e1e1-a39f8ffd8893"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "kbolC8XIhR3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf65bd5-7d79-4658-bb68-62fbd25dcb38"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AttentionModel(\n",
              "  (criterion): CrossEntropyLoss()\n",
              "  (lstm): LSTM(65, 32, batch_first=True, bidirectional=True)\n",
              "  (decoder_lstm_cell): LSTMCell(32, 64)\n",
              "  (output_layer): Linear(in_features=64, out_features=24, bias=True)\n",
              "  (fc1): Linear(in_features=96, out_features=32, bias=True)\n",
              "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = trainer.predict(model, predict_loader)\n",
        "\n",
        "prediction, attention_scores = zip(*output)"
      ],
      "metadata": {
        "id": "LsN71S9uQ9wo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "4e9cea3190fa47d58743afa69cf07744",
            "c5d057bf0905490e97b09ab6d4f241a4",
            "0496d10466294101b4960fe0d833f9c6",
            "871caec81dd9464ca9ef9c5a2da3136c",
            "049a678d38a546549dc85fb4296e588c",
            "e119104e88654beaa3b2c45174f6628f",
            "8148ad85b6584740aa552aaaed26d8a4",
            "ff1d99dce55d4451b9f9ab50b676fc81",
            "23d9160627a14f3a9b926e32391aabd3",
            "29b459e3ba57437a8429623c5fa1d2bc",
            "1b60508b1ac04c4db7aa84d1cabdb186"
          ]
        },
        "outputId": "99800367-ad51-45d8-95b8-6900c8151e89"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:lightning.pytorch.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e9cea3190fa47d58743afa69cf07744"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prayut<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "somchai<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "thanathon<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "nawin<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "suthep<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "prawit<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "chatchachatti<PAD><PAD><PAD><PAD><PAD><PAD>\n",
            "carunrot<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o3893RL1ZT8"
      },
      "source": [
        "## TODO 5: Show your visualization of attention scores on one of your example\n",
        "\n",
        "<font color='blue'>Paste your visualization image in MyCourseVille</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHysSqYJ1ZUA"
      },
      "source": [
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdktVnMv1ZTh"
      },
      "source": [
        "prediction, attention_scores = zip(*output)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_pred = prediction[-1]\n",
        "sample_pred = [p for p in sample_pred.cpu().numpy().tolist()[0] if p != 0]\n",
        "sample_attention_scores = attention_scores[-1]\n",
        "\n",
        "attn_viz = torch.stack(sample_attention_scores).squeeze().cpu().numpy()\n",
        "attn_viz = attn_viz[:len(EXAMPLES[-1])+1, :len(sample_pred)+1]\n",
        "\n",
        "output_text = [c for c in output_decode(sample_pred)]\n",
        "output_text.append(\"<PAD>\")\n",
        "xlabels = [c for c in EXAMPLES[-1]]\n",
        "xlabels.append(\"<PAD>\")\n",
        "print(output_text, xlabels)\n",
        "print(attn_viz.shape, len(EXAMPLES[-1]), len(sample_pred))\n",
        "print(attn_viz)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2MiIjJpzt4P",
        "outputId": "4fd06b00-4332-4951-f10d-c0994236b17f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['c', 'a', 'r', 'u', 'n', 'r', 'o', 't', '<PAD>'] ['จ', 'ร', 'ู', 'ญ', 'โ', 'ร', 'จ', 'น', '์', '<PAD>']\n",
            "(10, 9) 9 8\n",
            "[[9.9928349e-01 8.9558867e-05 8.9558867e-05 8.9558867e-05 8.9558867e-05\n",
            "  8.9558867e-05 8.9558867e-05 8.9558867e-05 8.9558867e-05]\n",
            " [6.1774105e-01 3.7679929e-01 2.7934171e-03 1.4028987e-03 1.3229156e-04\n",
            "  4.5092497e-04 1.5566275e-04 2.2478694e-04 2.9981640e-04]\n",
            " [2.3253502e-02 9.3890035e-01 2.6930373e-02 8.1430255e-03 2.0184080e-04\n",
            "  1.1841328e-03 4.5088105e-04 5.6733954e-04 3.6846986e-04]\n",
            " [2.5024993e-02 1.3561012e-01 6.9101131e-01 1.1356207e-01 3.1715676e-03\n",
            "  1.3251024e-02 5.4792147e-03 6.1255656e-03 6.7640557e-03]\n",
            " [1.4174275e-02 2.7571624e-02 2.3481464e-01 6.0327363e-01 3.9299605e-03\n",
            "  8.9811459e-02 7.8287851e-03 8.5649872e-03 1.0030669e-02]\n",
            " [5.8095353e-03 1.9588512e-03 3.7338335e-02 2.1840231e-01 1.6503515e-02\n",
            "  6.5303516e-01 2.6590124e-02 2.0940447e-02 1.9421710e-02]\n",
            " [3.5427902e-03 8.8361284e-04 1.4172532e-02 4.8981719e-02 2.3640496e-01\n",
            "  4.5784041e-01 1.2545796e-01 4.2885061e-02 6.9830939e-02]\n",
            " [3.0254722e-03 5.7802035e-04 2.2240507e-03 5.8830297e-03 1.9429603e-01\n",
            "  7.6235123e-02 5.3275919e-01 1.4499046e-01 4.0008664e-02]\n",
            " [1.1220701e-03 6.7756663e-04 1.3550809e-03 4.7533447e-03 7.3458567e-02\n",
            "  2.1255067e-02 3.5495558e-01 4.9973288e-01 4.2689912e-02]\n",
            " [3.9148140e-03 2.3502207e-03 5.3126737e-03 8.5897837e-03 5.2487042e-02\n",
            "  2.4398629e-02 2.5353327e-01 5.7651377e-01 7.2899826e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.heatmap(attn_viz, linewidth=0.5)\n",
        "ax.set_xticklabels(output_text,rotation=30)\n",
        "ax.set_yticklabels(xlabels,rotation=60)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "BF6HD99lYlgQ",
        "outputId": "59b2a8d5-c768-494f-a433-fb5f33f8d127"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1UkIsCztaMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}